---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
(cartes-statistiques-chapitre)=
# Cartes statistiques

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/elisabethloranger">
        <img src="https://avatars.githubusercontent.com/u/90270981?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>√âlisabeth Loranger</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/pbellec">
        <img src="https://avatars.githubusercontent.com/u/1670887?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Pierre bellec</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/eddyfortier">
        <img src="https://avatars.githubusercontent.com/u/72314243?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Eddy Fortier</b></sub>
      </a>
      <br />
        <a title="R√©vision du texte">üëÄ</a>
    </td>
  </tr>
</table>

```{warning}
Ce chapitre va √™tre mis √† jour √† l'automne 2022. En particulier les exercices vont √™tre r√©vis√©s, et certains exercices pourraient √™tre ajout√©s ou supprim√©s.
```

## Objectifs du cours

Dans ce chapitre, il sera question de l'utilisation du mod√®le de r√©gression pour g√©n√©rer des cartes statistiques c√©r√©brales de groupe. Les statistiques de groupe permettent de combiner les mesures du cerveau de plusieurs individus et ainsi de contraster des groupes (ex. groupe de personnes jeunes et groupe de personnes √¢g√©es) ou bien de tester l'association avec une variable continue (ex. l'√¢ge).

Les objectifs sp√©cifiques du cours portent sur les concepts suivants :
 * la r√©gression lin√©aire,
 * le mod√®le lin√©aire g√©n√©ral,
 * tests statistiques.

## R√©gression lin√©aire

### Variables
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Importer les librairies
import numpy as np
import matplotlib.pyplot as plt
from nilearn import datasets
from nilearn.input_data import NiftiMasker
from nilearn.image import get_data

# Charger les donn√©es
n_subjects = 100  
oasis_dataset = datasets.fetch_oasis_vbm(n_subjects=n_subjects)
gray_matter_map_filenames = oasis_dataset.gray_matter_maps
age = oasis_dataset.ext_vars['age'].astype(float)
sex = oasis_dataset.ext_vars['mf'] == b'F'

# Conversion des donn√©es en pandas dataframe
# Deux voxels int√©ressants ont √©t√© s√©lectionn√©s
import pandas as pd
coords = np.array([[ 29.,  10.,   4.], [-19.,   8., -11.]])
colors = ['blue', 'olive']

from nilearn import input_data
masker = input_data.NiftiSpheresMasker(coords)
gm = masker.fit_transform(gray_matter_map_filenames)
subject_label = [f'sub-{num}' for num in range(n_subjects)]
df = pd.DataFrame({
    "subject_label": subject_label,
    "age": age,
    "sexe": oasis_dataset.ext_vars['mf'],
    "MG1": gm[:, 0],
    "MG2": gm[:, 1]
    })

df["sexe"] = df["sexe"].replace([b'F', b'M'], value=['femelle', 'male'])

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

for i in range(0, 6):        
    nx = np.floor_divide(i, 3)
    ny = np.remainder(i, 3)
    ax = plt.subplot2grid((2, 5), (nx, ny), colspan=1)
    roi_img = plotting.plot_anat(
        gray_matter_map_filenames[i], cut_coords=[coords[nx][2]], figure=fig,
        axes=ax, display_mode='z', colorbar=False)
    roi_img.add_markers([coords[nx]], colors[nx], 100)

sns.set_theme(style="darkgrid")
ax = plt.subplot2grid((2, 5), (0, 3), colspan=2)
sns.histplot(
    df["MG1"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

ax = plt.subplot2grid((2, 5), (1, 3), colspan=2)
sns.histplot(
    df["MG2"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

from myst_nb import glue
glue("vbm-distribution-fig", fig, display=False)
```
```{glue:figure} vbm-distribution-fig
:figwidth: 800px
:name: vbm-distribution-fig
La position de deux voxels (illustr√©e √† l'aide d'un cercle bleu (haut) et d'un cercle olive (bas)) est ici superpos√©e sur des cartes de densit√© de mati√®re grise pour diff√©rents sujets du jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). √Ä droite, un histograme repr√©sente la distribution de la densit√© de mati√®re grise pour le voxel correspondant, √† travers un √©chantillon de 100 sujets. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Les concepts pr√©sent√©s dans ce chapitre s‚Äôappliquent √† la plupart des modalit√©s d'imagerie vues dans le cours de fa√ßon plus ou moins identique. Afin de rendre les choses un peu plus concr√®tes, nous allons ici nous int√©resser √† une analyse morphom√©trique de type VBM (IRM structurelle). Cette analyse utilise le jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). Des cartes de densit√© de mati√®re grise pour les donn√©es OASIS sont disponibles via la librairie [nilearn](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_oasis_vbm.html). Pour chaque voxel, on dispose d'une mesure locale de densit√© de mati√®re grise qui varie entre 0 et 1. Comme toutes les images des 100 participants OASIS utilis√©s dans cet exemple ont √©t√© recal√©es dans un m√™me espace st√©r√©otaxique, chaque voxel est associ√© √† une s√©rie de 100 mesures. Il s'agit de notre **variable d√©pendante**. On va par la suite chercher √† expliquer les variations de cette mesure √† travers les sujets √† l'aide d'autres variables, appel√©es les **pr√©dicteurs**. Pour notre exemple, nous allons d√©marrer avec l'√¢ge des participants qui varie ici de 20 ans √† 90 ans.

### Mod√®le lin√©aire
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# On r√©organise le DataFrame pour utiliser seaborn
df2 = df.melt(id_vars=["age", "sexe"], value_vars=["MG1", "MG2"], value_name="MG")
fig = sns.lmplot(x="age", y="MG", data=df2, col='variable',
           ci=None, scatter_kws={"s": 50, "alpha": 1})

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("regression-vbm-fig", fig.fig, display=False)           
```
```{glue:figure} regression-vbm-fig
:figwidth: 800px
:name: regression-vbm-fig
Exemple de r√©gression lin√©aire o√π la variable d√©pendante est la densit√© de mati√®re grise pour un voxel et le pr√©dicteur est l'√¢ge. Les valeurs de densit√© de mati√®re grise proviennent de 100 sujets de la base de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). Les deux voxels utilis√©s ici sont les m√™mes que ceux repr√©sent√©s dans la {numref}`vbm-distribution-fig` (voxel bleu √† gauche, voxel olive √† droite). La r√©gression lin√©aire est r√©alis√©e √† l'aide de la libraire [seaborn](https://seaborn.pydata.org) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Le concept soutenant le mod√®le de r√©gression est une √©quation, ou une sorte de loi, qui va tenter de pr√©dire la variable d√©pendante (ici, la densit√© de mati√®re grise) √† partir de pr√©dicteurs (par exemple, l'√¢ge). Mais contrairement √† une loi physique qui tente de repr√©senter une d√©pendance exacte (jusqu'√† un certain degr√©), la pr√©sente loi ne capture qu'une fraction de la variance de notre mesure. La loi va donc incorporer un certain bruit repr√©sentant toutes les sources de variabilit√© que l'on ne peut pas capturer avec notre relation. La relation math√©matique va prendre la forme suivante:

`densite_matiere_grise = b0 + b1 * age + e`

O√π

 * `densite_matiere_grise` est la densit√© de mati√®re grise mesur√©e pour un voxel
 * `age` est l'√¢ge du participant de recherche
 * `b0` est une valeur constante, appel√©e en anglais "intercept" (l'ordonn√©e √† l'origine). Cette valeur est identique pour tous les sujets. Dans ce cas-ci, elle repr√©senterait la densit√© de mati√®re grise observ√©e √† la naissance (`age=0`), en moyenne sur la population.
 * `b1` est une autre constante qui dans cet exemple mesure la r√©duction de mati√®re grise par ann√©e de vie (en moyenne sur la population).
 * `e` est un bruit de mesure qui capture toutes les variations de `densite_matiere_grise` que l'on ne peut pas expliquer avec `age`. Typiquement, on suppose que la moyenne de `e` dans la population est `0` et que la variance de `e` est identique pour tous les sujets, √©gale √† $\sigma^2$.

On ne connait √©videmment pas les coefficients `b0` et `b1`. Il sera n√©cessaire d'utiliser une proc√©dure statistique pour les `estimer`, c'est √† dire deviner (au mieux) leurs valeurs √† partir des donn√©es dont nous disposons. Par exemple, pour la r√©gion de couleur `olive` (graphe de droite dans {numref}`regression-vbm-fig`), on voit que l'on perd environ 25% de densit√© entre 20 ans et 90 ans (voir {numref}`regression-vbm-fig`). On perd donc environ 0.35% de densit√© de mati√®re grise par an, soit `b1 ~ -0.0035`. En utilisant cette valeur et en remarquant que la densit√© de mati√®re grise est d'√† peu pr√®s `0.85` √† `20` ans, on en d√©duit que la densit√© √† la naissance devrait √™tre `b0=0.92`. En pratique, la proc√©dure statistique va choisir les valeurs `b0` et `b1` pour minimiser l'amplitude des r√©sidus de la r√©gression:

`residus = densite_matiere_grise - b0 - b1 * age`

Une fois les coefficients `b0` et `b1` estim√©s, on peut tracer une droite qui repr√©sente les valeurs de densit√© de mati√®re grise pr√©dites √† partir de l'√¢ge des sujets (voir {numref}`regression-vbm-fig`). Si le mod√®le permet d'expliquer une partie importante de la variabilit√© de la variable d√©pendante, les points mesur√©s seront proches de la droite de pr√©diction.

### Analyse massivement univari√©e
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn.glm.second_level import make_second_level_design_matrix
design_df = df[["subject_label", "age"]].replace(['femelle', 'male'], value=[0., 1.])
design_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
from nilearn.glm.second_level import SecondLevelModel
second_level_model = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_matrix)
beta0 = second_level_model.compute_contrast(second_level_contrast="intercept", output_type="effect_size")
beta1 = second_level_model.compute_contrast(second_level_contrast="age", output_type="effect_size")

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

ax = plt.subplot2grid((2, 4), (0, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta0, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='intercept (b0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (1, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta1, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet de l\'age (b1)')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("b0-b1-fig", fig, display=False)           
```
```{glue:figure} b0-b1-fig
:figwidth: 600px
:name: b0-b1-fig
Cartes de param√®tres statistiques dans une r√©gression lin√©aire massivement univari√©e. Premi√®re ligne: intercept `b0`, deuxi√®me ligne: effet lin√©aire de l'√¢ge `b1`. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Pour l'instant, nous avons utilis√© un mod√®le de r√©gression pour deux voxels seulement. Mais une carte VBM peut inclure des centaines de milliers de voxels. Les logiciels de neuroimagerie permettent d'effectuer syst√©matiquement une r√©gression lin√©aire pour l'ensemble des voxels, simultan√©ment. Dans ce cas, on estime deux param√®tres pour chaque voxel: `b0` (l'intercept) et `b1` (l'effet de l'√¢ge). On va donc g√©n√©rer deux cartes statistiques s√©par√©es (voir {numref}`b0-b1-fig`). Ces deux cartes r√©capitulent donc des milliers de mod√®les de r√©gression diff√©rents. Comme les r√©gressions effectu√©es √† chaque voxel sont ind√©pendantes les unes des autres, on parle de mod√®le univari√©. L'autre option, le mod√®le multivari√©, chercherait plut√¥t √† combiner les valeurs obtenues √† diff√©rents voxels. De plus, comme on fait un tr√®s grand nombre de r√©gressions en m√™me temps, on parle de r√©gression **massivement univari√©e**.

```{admonition} Statistiques et multimodalit√©
:class: tip
:name: stats-multimodales
Le mod√®le de r√©gression est appliqu√© √† plusieurs modalit√©s de neuroimagerie. Dans ce chapitre, il est question d'un exemple utilisant la VBM. Mais le m√™me mod√®le fonctionne d√®s lors qu'on a une s√©rie de cartes pour diff√©rents sujets. Il pourrait par exemple √™tre utilis√© en [IRMf](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py) ou bien en TEP. Le m√™me type de mod√®le peut aussi s'appliquer √† des mesures prises sur des r√©cepteurs en imagerie optique ou des mesures moyennes sur un faisceau de fibres en IRMd. Le mod√®le de r√©gression est partout!
```

## Mod√®le lin√©aire g√©n√©ral

### Variables
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
sns.set_theme(style="ticks")

# Show the joint distribution using kernel density estimation
fig = sns.jointplot(
    data=df,
    x="age", y="MG1", hue="sexe",
    kind="scatter",
)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("age-sexe-fig", fig.fig, display=False)           
```
```{glue:figure} age-sexe-fig
:figwidth: 600px
:name: age-sexe-fig
Relation entre √¢ge, sexe et densit√© de mati√®re grise pour un voxel (le voxel de couleur bleu dans {numref}`vbm-distribution-fig`). Le graphique est r√©alis√© √† l'aide de la libraire [seaborn](https://seaborn.pydata.org) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

L'approche de r√©gression lin√©aire que l'on vient de voir est simple et puissante, mais elle est limit√©e √† deux variables. En neurosciences humaines, on ne se trouvera g√©n√©ralement pas dans ce cas. On va tr√®s souvent vouloir √©tudier des facteurs multiples de mani√®re conjointe. M√™me si la repr√©sentation du sexe des participants par une variable binaire est [tr√®s (tr√®s) simplificatrice](https://blogs.scientificamerican.com/sa-visual/visualizing-sex-as-a-spectrum/) - sans compter la diversit√© de l'identit√© de genre - nous allons quand m√™me essayer d'int√©grer le sexe (m√¢le vs femelle) dans notre analyse. La figure ci-dessus montre les distributions d'√¢ge et de mati√®re grise (pour le voxel bleu), s√©par√©es par sexe. Ce graphique sugg√®re que la distribution de mati√®re grise est peut-√™tre diff√©rente entre male et femelle, mais cette diff√©rence pourrait √©galement √™tre li√©e √† l'√¢ge. Le mod√®le lin√©aire g√©n√©ral nous permet d'int√©grer toutes ces variables dans une seule analyse.


### R√©gression multiple
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn.plotting import plot_design_matrix
design_df = df[["subject_label", "age", "sexe"]].replace(['femelle', 'male'], value=[0., 1.])
design_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
fig, ax = plt.subplots(ncols=5, figsize=(6, 12), sharey=True)
Y = df["MG1"].to_numpy()
X = design_matrix.to_numpy()
ax[0].plot(np.expand_dims(Y, axis=1), range(len(Y)))
ax[1].plot(X[:,0], range(len(Y)))
ax[2].plot(X[:,1], range(len(Y)))
ax[3].plot(X[:,2], range(len(Y)))
ax[0].set_ylabel('# sujet', fontsize=18)
ax[0].set_title('MG', fontsize=20)
ax[1].set_title('√Çge', fontsize=20)
ax[2].set_title('Sexe', fontsize=20)
ax[3].set_title('Intercept', fontsize=20)
plot_design_matrix(design_matrix, ax=ax[4])
ax[4].set_title('Matrice de dessein', fontsize=12)
ax[4].set_ylabel('# sujet')
plt.gca().invert_yaxis()
plt.tight_layout()

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("design-matrix-fig", fig, display=False)           
```
```{glue:figure} design-matrix-fig
:figwidth: 600px
:name: design-matrix-fig
Variables pour une r√©gression multiple. La variable d√©pendante est la densit√© de mati√®re grise pour un voxel (MG, le voxel de couleur bleu dans {numref}`vbm-distribution-fig`). Les autres colonnes repr√©sentent les variations de l'√¢ge, du sexe et de l'intercept √† travers les sujets (variables pr√©dictives). Les variables pr√©dictives sont g√©n√©ralement repr√©sent√©es de mani√®re plus compacte, sous la forme d'une image o√π la couleur de chaque pixel repr√©sente l'intensit√© du r√©gresseur. Le graphique est adapt√© d'un [code python](https://dartbrains.org/content/GLM.html) produit par l'√©quipe Dartbrains, ainsi que d'un [tutoriel nilearn](https://nilearn.github.io/glm/first_level_model.html) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

D'un point de vue math√©matique, le mod√®le de r√©gression multiple, parfois appel√© mod√®le lin√©aire g√©n√©ral, consiste simplement √† incorporer plus de variables dans la "loi" qui tente de pr√©dir la variable d√©pendante √† partir des r√©gresseurs:
`densite_matiere_grise = b0 + b1 * age + b2 * sexe + e`

Le seul nouveau coefficient est `b2`, qui dans ce cas mesure la diff√©rence entre la moyenne de mati√®re grise entre les femelles (cod√©es avec un 0 dans le mod√®le) et les m√¢les (cod√©s avec un 1 dans le mod√®le), **apr√®s un ajustement pour l'√¢ge des sujets**. Ce type de codage est utilis√© avec les donn√©es cat√©gorielles et est appel√© "dummy variable" en anglais. Il permet d'int√©grer des tests de diff√©rence de moyenne entre les groupes dans un mod√®le de r√©gression.

```{admonition} R√©gression multiple et statistiques classiques
:class: tip
:name: stats-regression
Le mod√®le de r√©gression multiple est tr√®s flexible. Il est possible de formuler la plupart des tests statistiques classiques tels que l'analyse de variance (ANOVA) ou bien le test d'√©galit√© des moyennes de Student (t-test) √† l'aide du mod√®le de r√©gression lin√©aire. Voir ce [guide](https://lindeloev.github.io/tests-as-linear/) pour plus de d√©tails.
```

### Cartes statistiques
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
second_level_model = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_matrix)
beta0 = second_level_model.compute_contrast(second_level_contrast="intercept", output_type="effect_size")
beta1 = second_level_model.compute_contrast(second_level_contrast="age", output_type="effect_size")
beta2 = second_level_model.compute_contrast(second_level_contrast="sexe", output_type="effect_size")

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

ax = plt.subplot2grid((2, 4), (0, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    beta0, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='intercept (b0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (0, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    beta1, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet de l\'age (b1)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (1, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    beta2, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet du sexe (b2)')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("multi-regression-fig", fig, display=False)           
```
```{glue:figure} multi-regression-fig
:figwidth: 800px
:name: multi-regression-fig
Cartes de param√®tres statistiques dans une r√©gression lin√©aire multiple massivement univari√©e. Haut gauche: intercept `b0`, haut droite: effet lin√©aire de l'√¢ge `b1`, bas gauche: effet lin√©aire du sexe `b2`. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

Une caract√©ristique qui peut √™tre l√©g√®rement contre-intuitive avec la r√©gression multiple est que la carte pr√©sentant l'effet de l'√¢ge ici est diff√©rente de celle pr√©sent√©e dans la section portant sur la r√©gression simple. En effet, l'effet de l'√¢ge est maintenant √©valu√© _apr√®s avoir pris en compte des diff√©rences de sexe_. Malgr√© cela, le r√©sultat de la r√©gression n'a pas chang√© de mani√®re frappante: le cortex s'atrophie avec l'√¢ge (en bleu), alors que le liquide c√©phalo-rachidien s'√©tend (en rouge). Ce qui apparait comme une expansion de la mati√®re grise refl√®te probablement des effets de volume partiel et des tissus classifi√©s incorrectement comme de la mati√®re grise. L'analyse sur la variable `sexe` montre que la densit√© de mati√®re grise est plus √©lev√©e (en moyenne) dans le cortex chez les hommes, alors que la tendance est invers√©e au niveau du cervelet.

## Tests statistiques

### Tests t et valeur p
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]

from nilearn.image import math_img
z_score = second_level_model.compute_contrast(second_level_contrast="age", output_type="z_score")
p_value = second_level_model.compute_contrast(second_level_contrast="age", output_type="p_value")
neg_log_pval = math_img("-np.log10(np.minimum(1, img))", img=p_value)

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 6))

ax = plt.subplot2grid((1, 4), (0, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test (√¢ge)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((1, 4), (0, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    neg_log_pval, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='significativit√© (-log10(p))')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("tmap-pval-fig", fig, display=False)           
```
```{glue:figure} tmap-pval-fig
:figwidth: 800px
:name: tmap-pval-fig
 Tests statistiques sur la significativit√© de l'association entre densit√© de mati√®re grise et √¢ge. Test t de Student (haut) et log10(p) (bas). Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Une fois que l'on a estim√© l'effet de certaines variables explicatives (par exemple, l'√¢ge) sur notre variable d√©pendante (par exemple, la densit√© de mati√®re grise), il est n√©cessaire de tester la **significativit√©** de cet effet. √Ä cette fin, on utilise l'amplitude des r√©sidus pour estimer la taille d'effet que l'on pourrait observer par chance, si uniquement ces r√©sidus √©taient pr√©sents. On en d√©duit un test `t` de Student, qui se comporte comme une [loi normale](https://fr.wikipedia.org/wiki/Loi_normale) quand le nombre de sujets est grand. Pour chaque voxel, on a donc une statistique `t` diff√©rente, et on peut calculer la probabilit√© `p` d'observer cette statistique sous l'**hypoth√®se nulle**, o√π l'effet de la variable explicative est exactement z√©ro.

### Hypoth√®se nulle
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]

from numpy.random import seed
from numpy.random import shuffle
# seed random number generator
seed(1)
design_rand_df = df[["subject_label", "age"]].replace(['femelle', 'male'], value=[0, 1])
design_rand_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
shuffle(design_rand_matrix["age"].to_numpy())

second_level_model_rand = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model_rand = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_rand_matrix)

z_score_rand = second_level_model_rand.compute_contrast(second_level_contrast="age", output_type="z_score")
p_value_rand = second_level_model_rand.compute_contrast(second_level_contrast="age", output_type="p_value")
neg_log_pval_rand = math_img("-np.log10(np.minimum(1, img))", img=p_value_rand)

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 6))

ax = plt.subplot2grid((1, 4), (0, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score_rand, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test (H0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((1, 4), (0, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    neg_log_pval_rand, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='significativit√© H0 (-log10(p))')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("null-fig", fig, display=False)           
```
```{glue:figure} null-fig
:figwidth: 800px
:name: null-fig
 Tests statistiques sur la significativit√© de l'association entre densit√© de mati√®re grise et √¢ge, sous l'hypoth√®se nulle o√π il n'existe aucune association. Les donn√©es d'√¢ge ont √©t√© permut√©es al√©atoirement entre les sujets. Test t de Student (haut) et log10(p) (bas). Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Au coeur de l'interpr√©tation de la valeur `p`, il y a ce qu'on appelle l'**hypoth√®se nulle**. Pour essayer de comprendre ce que cela veut dire, faisons une exp√©rience. Nous allons recommencer toute la proc√©dure d'estimation de l'effet de l'√¢ge sur la densit√© de mati√®re grise. Mais cette fois ci, au lieu d'utiliser l'√¢ge r√©el des sujets, nous allons m√©langer ces valeurs al√©atoirement (on parle de [permutations](https://fr.wikipedia.org/wiki/Permutation)). La distribution des tests `t` et des valeurs `p` est pr√©sent√©e dans la {numref}`null-fig`. De mani√®re frappante, les valeurs `t` sont beaucoup plus petites avec les valeurs d'√¢ge al√©atoires que lorsqu'on a fait l'analyse avec les vraies valeurs, mais certaines valeurs restent √©lev√©es. On a r√©alis√© une exp√©rience sous l'hypoth√®se nulle, o√π il n'existe aucune association avec l'√¢ge. La valeur `p` nous indique la **fr√©quence** avec laquelle on trouvera des valeurs d'effet de l'√¢ge plus √©lev√©es sous l'hypoth√®se nulle que dans l'√©chantillon original. Pour estimer cela directement, il faudrait recommencer l'exp√©rience que l'on vient de faire avec des milliers de permutations! Mais il existe aussi des m√©thodes approxim√©es plus rapide.

### Comparaisons multiples
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]

from nilearn.glm import threshold_stats_img
from scipy.stats import norm
p_val = 0.001
p001_uncorrected = norm.isf(p_val)
p_val = 0.05
p05_uncorrected = norm.isf(p_val)

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 18))

ax = plt.subplot2grid((3, 4), (0, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score, threshold=p05_uncorrected, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test, p<0.05')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((3, 4), (1, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score, threshold=p001_uncorrected, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test, p<0.001')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((3, 4), (2, 2), colspan=2)
thresholded_map, threshold = threshold_stats_img(
    z_score, alpha=.05, height_control='bonferroni')
roi_img = plotting.plot_stat_map(
    z_score, threshold=threshold, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test, p<0.05 corrig√©')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((3, 4), (0, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score_rand, threshold=p05_uncorrected, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test (H0), p<0.05')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((3, 4), (1, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    z_score_rand, threshold=p001_uncorrected, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test (H0), p<0.001')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((3, 4), (2, 0), colspan=2)
thresholded_map_rand, threshold_rand = threshold_stats_img(
    z_score_rand, alpha=.05, height_control='bonferroni')
roi_img = plotting.plot_stat_map(
    z_score_rand, threshold=threshold_rand, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='t-test (H0), p<0.05 corrig√©')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("threshold-fig", fig, display=False)           
```
```{glue:figure} threshold-fig
:figwidth: 800px
:name: threshold-fig
 Effet de diff√©rentes strat√©gies de seuillage sur l'association entre l'√¢ge et la densit√© de mati√®re grise. √Ä gauche: donn√©es sous l'hypoth√®se nulle (valeurs d'√¢ge permut√©e au travers des sujets). √Ä droite: donn√©es originales. Ligne 1: seuil `p<0.05` non corrig√© pour les comparaisons multiples; ligne 2: seuil `p<0.001` non corrig√© pour les comparaisons multiples; seuil `p<0.05` corrig√© pour les comparaisons multiples par l'approche de Bonferroni. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_thresholding.html#sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

Maintenant que l'on a discut√© de l'interpr√©tation de la valeur `p`, on doit maintenant d√©cider d'un seuil √† appliquer sur les valeurs `p`. Si l'on utilise le seuil habituel `p<0.05`, cela signifie que pour 20 permutations, on d√©tectera une association 1 fois (en moyenne) pour un voxel donn√©. Mais comme on a des milliers de voxels dans le cerveau, cela veut dire que l'on va d√©tecter 5% du cerveau (en moyenne) pour chaque permutation! C'est ce que l'on observe (et m√™me plus) dans la figure en haut √† gauche {numref}`threshold-fig`. Il s'agit du **probl√®me de comparaisons multiples**, et plus on fait de tests, plus ce probl√®me est important.

Si l'on abaisse le seuil √† `p<0.001`, on ne d√©tecte plus que 0.1% du cerveau (en moyenne) sous l'hypoth√®se nulle, et on observe en effet une r√©duction du nombre de voxels dans la figure de gauche, 2i√®me ligne {numref}`threshold-fig`.

La m√©thode la plus simple pour corriger du probl√®me de comparaisons multiples est d'utiliser un seuil corrig√© `p<0.05/N`, o√π N est le nombre de comparaisons (c'est √† dire de tests). Dans notre cas, on a approximativement 100,000 voxels, donc on va utiliser `p<0.0000001`! Avec cette strat√©gie, aucun voxel ne passe le seuil dans notre exp√©rience sous l'hypoth√®se nulle, voir figure en bas √† gauche {numref}`threshold-fig`. En g√©n√©ral c'est ce qui se passera (en moyenne) pour 19/20 permutations.

Si l'on observe maintenant l'effet de ces diff√©rentes strat√©gies sur les donn√©es originales, on observe que plus le seuil `p` est petit, moins on d√©tecte d'effets significatifs. Malgr√© tout, m√™me avec `p<0.05` corrig√© par l'approche de Bonferroni, on d√©tecte toujours les effets principaux de l'√¢ge.

```{admonition} Compromis r√©solution / puissance
:class: tip
:name: resolution-power
En r√®gle g√©n√©ral, on doit faire un compromis entre la r√©solution (notre capacit√© √† d√©tecter des effets dans de petites r√©gions du cerveau) et la puissance statistique (notre capacit√© √† d√©tecter des effets de petite taille). Si l'on veut une excellente r√©solution, on fait des tests √† tous les voxels, mais on doit corriger pour un tr√®s grand nombre de comparaisons multiples. En revanche, si l'on ne teste qu'une valeur moyenne sur une r√©gion, on n'a qu'un seul test et aucune correction √† appliquer, mais on ne sait pas ce qui se passe dans le reste du cerveau, ou √† l'int√©rieur de cette r√©gion.
```
## Conclusion

* Le mod√®le de r√©gression simple permet de pr√©dire les observations d'une variable d√©pendante √† partir d'une varible explicative.
* Ce mod√®le est appliqu√© ind√©pendamment √† chaque voxel (approche massivement multivari√©e).
* Il est possible d'utiliser le mod√®le lin√©aire g√©n√©ral pour tester simultan√©ment l'effet de plusieurs variables explicatives sur la variable d√©pendante.
* Quand on effectue un grand nombre de tests statistiques √† chaque voxel, il faut modifier le seuil de significativit√© du test (probl√®me de comparaisons multiples).

## Exercices

```{admonition} Exercice 9.1
:class: note
On souhaite comparer la connectivit√© entre deux groupes de sujets, jeunes vs √¢g√©s.
D√©crivez les variables pr√©dictives √† inclure dans un mod√®le de r√©gression.  
Quelles autres variables vous semblent-elles importantes √† inclure dans le mod√®le?
```

```{admonition} Exercice 9.2
:class: note
Vrai/faux (expliquez pourquoi)
Le mod√®le de r√©gression peut √™tre utilis√© pour effectuer des statistiques de groupe pour les types de mesures suivantes‚Ä¶ (vrai/faux)
 * IRMf
 * IRM T1 (VBM)
 * IRM T1 (volum√©trie)
 * IRM T1 (√©paisseur corticale)
 * Donn√©es comportementales
 * Tomographie par √©mission de positrons
 * Imagerie optique
 * Imagerie de diffusion
```

```{admonition} Exercice 9.3
:class: note
Vrai/faux. On observe une diff√©rence de moyenne entre deux groupes, et l‚Äôon effectue un test statistique qui nous donne une valeur p.
 * La valeur p est la probabilit√© qu‚Äôil n‚Äôy ait pas de vraie diff√©rence.
 * Une faible valeur p indique une forte probabilit√© qu‚Äôil y ait une vraie diff√©rence.
 * La valeur p indique la probabilit√© d‚Äôobserver cette diff√©rence, au moins, s‚Äôil n‚Äôexistait vraiment aucune diff√©rence entre les deux groupes.
```

```{admonition} Exercice 9.4
:class: note
Vrai/faux. Un probl√®me de comparaisons multiples signifie.
 * Qu‚Äôon effectue de mani√®re r√©p√©t√©e des test statistiques g√©n√©rant une valeur p.
 * Que l‚Äôon r√©p√®te un test statistique √† chaque voxel dans une image du cerveau, par exemple.
 * Que l‚Äôon teste beaucoup d‚Äôhypoth√®ses dans un article, par exemple.
 * Que l‚Äôon a quatre sous-groupes, et que l‚Äôon compare chacune des trois paires possibles de sous-groupes, par exemple.
```

```{admonition} Exercice 9.5
:class: note
Classer les analyses suivantes du plus petit au plus grand, en fonction du nombre de comparaisons multiples impliqu√©es. Indiquez le nombre approximatif de comparaisons.
 * On compare la densit√© de mati√®re grise entre deux groupes de sujets √† chaque voxel du cerveau.
 * On compare le m√©tabolisme du glucose entre deux groupes de sujets √† chaque voxel du cerveau, √† l‚Äôaide du FDG-TEP.
 * On compare le volume de r√©gions c√©r√©brales entre deux groupes de sujets, √† partir d‚Äôun atlas qui comprend 90 r√©gions.
 * On compare le volume de l‚Äôhippocampe entre deux groupes de sujets.
```

```{admonition} Exercice 9.6
:class: note
Pour r√©pondre aux questions de cet exercice, lisez d'abord l'article *Tau pathology in cognitively normal older adults* de Ziontz et collaborateurs (disponible comme [preprint](https://doi.org/10.1101/611186 ) sur Biorxiv sous licence CC0 et publi√© dans le journal Alzheimer's & Dementia: Diagnosis, Assessment & Disease Monitoring [doi](https://doi.org/10.1016/j.dadm.2019.07.007). Les questions suivantes requi√®rent des r√©ponses √† d√©veloppement court.
- Quelle est la variable d√©pendante du mod√®le lin√©aire?
- Quelles variables explicatives sont incluses dans le mod√®le lin√©aire?
- Sait on combien de comparaisons multiples sont faites?
- Comment est ce que les comparaisons multiples sont corrig√©es?
```
